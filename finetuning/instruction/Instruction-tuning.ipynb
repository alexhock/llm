{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ac4660-cf30-4a9c-828c-e06573f40a19",
   "metadata": {},
   "source": [
    "# Instruction tuning using Lora and the Dolly dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f364f6d-9628-45d8-85c8-b8e787c5f570",
   "metadata": {},
   "source": [
    "https://www.philschmid.de/instruction-tune-llama-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d887b5-39e5-4b37-aaa1-065e55c6188c",
   "metadata": {},
   "source": [
    "## Load the finetuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc6594-4904-4fa7-938e-3432a9ab146d",
   "metadata": {},
   "source": [
    "Download the model from Azure ML\n",
    "az ml job download --name <run id/job name> --resource-group <> --workspace-name <>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23504911-a7d8-4e8a-855a-4778ff528ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"../models/artifacts/outputs/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "053d06aa-0609-4f48-9295-246e8b1ee684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    #low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    #load_in_4bit=True,\n",
    ") \n",
    "\n",
    "model.to('cuda:0');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2b5193f-5676-4350-b81f-19effefa84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80e6be-1095-47cf-b349-3e207cd0326b",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e15f3e1-f21d-4b7c-91c2-34bdeebc231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randrange\n",
    "\n",
    "# Load dataset from the hub and get a sample\n",
    "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7f0a040-e159-41e9-bcae-fec1305e8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(text):\n",
    "    p = f\"\"\"### Instruction:\n",
    "Use the Input below to create an instruction, which could have been used to generate the input using an LLM. \n",
    "\n",
    "### Input:\n",
    "{text}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    return p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60351c39-7891-4c34-b893-bc3aee59632a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Who directed the episode of Game of Thrones where Jon Snow and Tormund Giantsbane go to ask the wildlings to settle beyond the Wall, but end up encountering White Walkers and the Night King?',\n",
       " 'context': '',\n",
       " 'response': 'Season five, episode eight entitled \"Hardhome\"',\n",
       " 'category': 'open_qa'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset[randrange(len(dataset))]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd4278ed-0639-4ac2-89b5-9a9114776295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = create_prompt(sample['response'])\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "# with torch.inference_mode():\n",
    "outputs = model.generate(input_ids=input_ids, max_new_tokens=100, do_sample=True, top_p=0.9,temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d6195fd-3b7b-4200-a6d4-1abd7a637234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "Season five, episode eight entitled \"Hardhome\"\n",
      "\n",
      "Generated instruction:\n",
      "What is the episode where Jon Snow travels north of the Wall to speak with the leader of the wildlings, Tormund Giantsbane, beyond the Wall?\n",
      "\n",
      "Ground truth:\n",
      "Who directed the episode of Game of Thrones where Jon Snow and Tormund Giantsbane go to ask the wildlings to settle beyond the Wall, but end up encountering White Walkers and the Night King?\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prompt:\\n{sample['response']}\\n\")\n",
    "print(f\"Generated instruction:\\n{tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]}\")\n",
    "print(f\"Ground truth:\\n{sample['instruction']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7e25d-f21e-43bd-9aa4-8e8cc0971ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
