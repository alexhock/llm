$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json

# Name of the experiment where all jobs will end up in the Azure ML dashboard
experiment_name: LLM-Finetuning-MultiGPU
display_name: Intel/neural-chat-7b-v3-3-multigpu-reddit

# What to run
command: >-  
    accelerate launch
    --config_file accelerate_config.yaml
    --num_machines ${{inputs.num_machines}}
    --num_processes ${{inputs.num_processes}}
    --machine_rank $NODE_RANK
    --main_process_ip $MASTER_ADDR
    --main_process_port $MASTER_PORT
    main.py --filename ${{inputs.filename}} --model_name="Intel/neural-chat-7b-v3-3" --epochs=3
inputs:
  num_machines: 1 
  num_processes: 2 
  filename: ./reddit-data.csv

code: .

environment:
  build:
    path: ./environment

compute: azureml:A100

distribution:
  type: pytorch                    # Azure ML will use this to configure the job for pytorch e.g. initialises NODE_RANK etc above.
  process_count_per_instance: 1    # Azure ML will create this number of processes per node for the job. We leave subprocess creation to Accelerate using the inputs.num_processes variable)
resources:
  instance_count: 1                # number of nodes to use in the cluster