{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e223f598-13e6-4e5b-86b3-99d918dcb818",
   "metadata": {},
   "source": [
    "# Inference and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8173511-676d-4355-bfd8-fa21bd668377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import bfloat16\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig, PeftModel\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213a009-5a3e-4e52-a458-3b0300c122bd",
   "metadata": {},
   "source": [
    "## Code to load huggingface models with and without lora trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509c3fab-b5b1-4d90-b5d4-9e5e5f9a1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_lora_model(\n",
    "        llm_model_name: str,\n",
    "        lora_model_weights: str,\n",
    "        device: str = \"auto\",\n",
    "        use_4bit: bool = False,\n",
    "        use_8bit: bool = False\n",
    "    ):\n",
    "\n",
    "    model_config = transformers.AutoConfig.from_pretrained(\n",
    "        llm_model_name,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    # quantization - https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
    "    bnb_config = None\n",
    "    if use_4bit:\n",
    "        bnb_config = transformers.BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            # # Commented to test V100\n",
    "            #bnb_4bit_compute_dtype=bfloat16\n",
    "        )\n",
    "    \n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        llm_model_name,\n",
    "        load_in_8bit=use_8bit,\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        device_map=device,\n",
    "        # Only put quantize here!\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "    \n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        llm_model_name,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    # Add the Lora weights to the base model\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model=model,\n",
    "        model_id=lora_model_weights,\n",
    "    )\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def load_huggingface_base_model(\n",
    "    model_name:str=\"microsoft/phi-2\", \n",
    "    dtype:str=\"bfloat16\", \n",
    "    use_4bit:bool=False, use_8bit:bool=False\n",
    "    ):\n",
    "\n",
    "    compute_dtype = getattr(torch, dtype)\n",
    "\n",
    "    bnb_config=None\n",
    "    if use_4bit:\n",
    "        bnb_config=BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=False,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=compute_dtype,\n",
    "        )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        load_in_8bit=use_8bit,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config, \n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                            trust_remote_code=True,\n",
    "                                            )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def get_pipeline(model, tokenizer, max_tokens=25, temp=0.0):\n",
    "    pipe = pipeline(task=\"text-generation\", \n",
    "        model=model, \n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=max_tokens, \n",
    "        temperature=temp,\n",
    "    )    \n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa26c9-61fb-4f00-bf96-d6bd537f7b5b",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "\n",
    "The data consists of sentences. These are then put in prompts. \n",
    "\n",
    "The training set includes the correct sentiment/label; The test set does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22287c4-0b1a-4919-abe0-f250964ca5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( ADP News ) - Finnish handling systems provider Cargotec Oyj ( HEL : CGCBV ) announced on Friday it won orders worth EUR 10 million ( USD 13.2 m ) to deliver linkspans to Jordan , Morocco and Ireland .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"( ADP News ) - Finnish handling systems provider Cargotec Oyj ( HEL : CGCBV ) announced on Friday it won orders worth EUR 10 million ( USD 13.2 m ) to deliver linkspans to Jordan , Morocco and Ireland .\"\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a55cac9-1a80-4136-95ab-37e4684dc576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the following phrase: '( ADP News ) - Finnish handling systems provider Cargotec Oyj ( HEL : CGCBV ) announced on Friday it won orders worth EUR 10 million ( USD 13.2 m ) to deliver linkspans to Jordan , Morocco and Ireland .' is \n",
      "\n",
      " Positive\n",
      "            \n",
      " Negative\n",
      "            \n",
      " Neutral\n",
      "            \n",
      " Cannot be determined\n",
      "\n",
      "Solution: The correct option is\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"The sentiment of the following phrase: '{sentence}' is \n",
    "\n",
    " Positive\n",
    "            \n",
    " Negative\n",
    "            \n",
    " Neutral\n",
    "            \n",
    " Cannot be determined\n",
    "\n",
    "Solution: The correct option is\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24eea93-4c05-4c73-a230-34900708db2f",
   "metadata": {},
   "source": [
    "## Base Model Load and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98cdb265-8230-420b-807b-e633d8401e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/phi-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4b7b83-94fc-4930-bc31-7efc311e48c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.20it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "base_model, base_tokenizer = load_huggingface_base_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eddfd22d-c700-49d8-b2a6-82ff5bd0e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipe = get_pipeline(base_model, base_tokenizer, max_tokens=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58af35fb-2b16-409f-9c32-59d9d965623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the following phrase: '( ADP News ) - Finnish handling systems provider Cargotec Oyj ( HEL : CGCBV ) announced on Friday it won orders worth EUR 10 million ( USD 13.2 m ) to deliver linkspans to Jordan , Morocco and Ireland .' is \n",
      "\n",
      " Positive\n",
      "            \n",
      " Negative\n",
      "            \n",
      " Neutral\n",
      "            \n",
      " Cannot be determined\n",
      "\n",
      "Solution: The correct option is  C Neutral\n",
      "\n",
      "Explanation: The sentiment of a phrase is the attitude or emotion that the speaker or writer conveys through their words. It can be positive, negative, or neutral, depending on the tone and context of the phrase. To determine the sentiment of a phrase, we can look for clues such as the choice of words, the punctuation, the modifiers, and the comparison\n"
     ]
    }
   ],
   "source": [
    "result = base_pipe(prompt, pad_token_id=base_pipe.tokenizer.eos_token_id)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbccf14c-18d7-40b4-aab7-a857753ed4fd",
   "metadata": {},
   "source": [
    "#### Things to note about the base model response above.\n",
    "- It's wrong. The sentence is positive from a financial point of view\n",
    "- It adds the C which isn't in the prompt but also the Explanation starts with 'Explanation'. These come from the original training.\n",
    "- The explanation is wrong!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6606ac7c-4981-4064-9e8b-7028b6753b36",
   "metadata": {},
   "source": [
    "## Finetuned Lora Model Load and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1978a4a-590f-42fc-bc57-5667b4582ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder where the lora model weights were saved after training using code: trainer.model.save_pretrained(\"phi2_sentiment_model\")\n",
    "lora_model_fldr = \"./phi2_sentiment_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d191a38-ac51-4b88-846a-0f314c2af76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.20it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "lora_model, lora_tokenizer = load_lora_model(model_name, lora_model_fldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ccac8c1-3968-41ac-aca5-5c3ddb4ebe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'PhiForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "ft_lora_pipe = get_pipeline(lora_model, lora_tokenizer, max_tokens=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94dae9b9-b060-4f93-9b8a-5e6c744e3e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the following phrase: '( ADP News ) - Finnish handling systems provider Cargotec Oyj ( HEL : CGCBV ) announced on Friday it won orders worth EUR 10 million ( USD 13.2 m ) to deliver linkspans to Jordan , Morocco and Ireland .' is \n",
      "\n",
      " Positive\n",
      "            \n",
      " Negative\n",
      "            \n",
      " Neutral\n",
      "            \n",
      " Cannot be determined\n",
      "\n",
      "Solution: The correct option is positive. The phrase 'won orders worth EUR 10 million ( USD 13.2 m )' indicates that the company received a positive amount of money from the customers. Therefore, the sentiment of the phrase is positive.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = ft_lora_pipe(prompt, pad_token_id=ft_lora_pipe.tokenizer.eos_token_id)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a649a-e262-4034-b04c-64c831d270be",
   "metadata": {},
   "source": [
    "#### Things to note about the fine-tuned response\n",
    "- It's correct, there is no 'Explanation:'. The fine-tuning removed that and the response is closer to the training set prompt.\n",
    "- Also the reasoning is correct and different (even though we didn't fine-tune on reasoning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c49bda-7b47-46bb-ada3-a05752af1ba7",
   "metadata": {},
   "source": [
    "## Calling Finetuned Lora model from Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e8dfed1-67e0-4d9a-9f35-2f28c8bd8fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" positive. The phrase 'won orders worth EUR 10 million ( USD 13.2 m )' indicates that the company received a positive amount of money from the customers. Therefore, the sentiment of the phrase is positive.\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Langchain\n",
    "langchain_pipe = HuggingFacePipeline(pipeline=ft_lora_pipe)\n",
    "langchain_pipe.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c9a5b5a-691f-465c-8bf9-f26a362ba875",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.distributed' has no attribute 'is_world_process_zero'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_world_process_zero\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.distributed' has no attribute 'is_world_process_zero'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de90822-fd2e-4ba3-90e1-6b494005611f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
