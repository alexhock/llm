{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import fitz\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = \"llama2.pdf\"\n",
    "\n",
    "# Split the base name and extension\n",
    "output_directory_path, _ = os.path.splitext(pdf_file)\n",
    "\n",
    "if not os.path.exists(output_directory_path):\n",
    "    os.makedirs(output_directory_path)\n",
    "\n",
    "image_paths = []\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_document = fitz.open(pdf_file)\n",
    "\n",
    "# Iterate through each page and convert to an image\n",
    "for page_number in range(pdf_document.page_count):\n",
    "    # Get the page\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Convert the page to an image\n",
    "    pix = page.get_pixmap()\n",
    "\n",
    "    # Create a Pillow Image object from the pixmap\n",
    "    image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    # Save the image\n",
    "    image.save(f\"./{output_directory_path}/page_{page_number + 1}.png\")\n",
    "\n",
    "# Close the PDF file\n",
    "pdf_document.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9u2A3GrLzwjylNl2sLY4oPpERxHII', 'object': 'chat.completion', 'created': 1723141703, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '```markdown\\n# Contents\\n\\n1. Introduction ......................................................... 3\\n\\n2. Pretraining .......................................................... 5  \\n   2.1 Pretraining Data ................................................. 5  \\n   2.2 Training Details ................................................. 5  \\n   2.3 LLAMA 2 Pretrained Model Evaluation ............................... 7  \\n\\n3. Fine-tuning ........................................................... 8  \\n   3.1 Supervised Fine-Tuning (SFT) ..................................... 9  \\n   3.2 Reinforcement Learning with Human Feedback (RLHF) .................. 9  \\n   3.3 System Message for Multi-Turn Consistency ........................ 16  \\n   3.4 RLHF Results .................................................... 17  \\n\\n4. Safety ............................................................... 20  \\n   4.1 Safety in Pretraining ............................................ 20  \\n   4.2 Safety Fine-Tuning ............................................... 23  \\n   4.3 Red Teaming ..................................................... 28  \\n   4.4 Safety Evaluation of LLAMA 2-CHAT ............................... 29  \\n\\n5. Discussion ........................................................... 32  \\n   5.1 Learnings and Observations ....................................... 32  \\n   5.2 Limitations and Ethical Considerations ............................ 34  \\n   5.3 Responsible Release Strategy .................................... 35  \\n\\n6. Related Work ......................................................... 35  \\n\\n7. Conclusion ........................................................... 36  \\n\\nA. Appendix ............................................................ 46  \\n   A.1 Contributions ................................................... 46  \\n   A.2 Additional Details for Pretraining ............................... 47  \\n   A.3 Additional Details for Fine-tuning ................................ 51  \\n   A.4 Additional Details for Safety .................................... 58  \\n   A.5 Data Annotation .................................................. 72  \\n   A.6 Dataset Contamination .......................................... 75  \\n   A.7 Model Card ....................................................... 77  \\n```', 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 25516, 'completion_tokens': 397, 'total_tokens': 25913}, 'system_fingerprint': 'fp_507c9469a1'}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "# OpenAI API key\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def extract_content_from_image(image_path, api_key):\n",
    "  # Path to your image\n",
    "  #image_path = \"./llama2/page_2.png\"\n",
    "\n",
    "  # Getting the base64 string\n",
    "  base64_image = encode_image(image_path)\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"extract the contents of the image as markdown\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 4000\n",
    "  }\n",
    "\n",
    "  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "  r = response.json()\n",
    "  return r\n",
    "\n",
    "  #print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "def list_png_files(folder_path):\n",
    "    # Get the list of all files in the specified folder\n",
    "    files = os.listdir(folder_path)\n",
    "            \n",
    "    # Filter the list to include only .png files\n",
    "    png_files = [os.path.join(folder_path, file) for file in files if file.endswith('.png')]\n",
    "                        \n",
    "    return png_files\n",
    "\n",
    "image_paths=list_png_files(output_directory_path)\n",
    "\n",
    "api_key = ''\n",
    "\n",
    "for image_path in image_paths:\n",
    "    r = extract_content_from_image(image_path, api_key)\n",
    "    md = r['choices'][0]['message']['content']\n",
    "    with open(image_path.replace('.png', '.md'), 'w') as f:\n",
    "        f.write(md)     \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
