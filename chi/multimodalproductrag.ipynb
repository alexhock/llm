{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a RAG Pipeline over IKEA Product Instruction Manuals\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_parse/blob/main/examples/multimodal/product_manual_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cookbook shows how to use LlamaParse and OpenAI's multimodal models to query over IKEA instruction manual PDFs, which mainly contain images and diagrams to show how one can assemble the product.\n",
    "\n",
    "LlamaParse and multimodal LLMs can interpret these diagrams and translate them into textual instructions. With textual assistance, confusing visual instructions within the IKEA product manuals can be made easier to understand and interpret. Additionally, textual instructions can be helpful for those who are visually impaired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Setup\n",
    "\n",
    "Install LlamaIndex, download the data, and apply `nest_asyncio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-eu7l0d13\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-eu7l0d13\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: llama-index in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.10.62)\n",
      "Requirement already satisfied: llama-parse in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.4.9)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.2.9)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.1.13)\n",
      "Requirement already satisfied: llama-index-core==0.10.62 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.10.62)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.1.11)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.2.7)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.27 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.1.29)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.1.32)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.62->llama-index) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (3.10.1)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (2024.6.1)\n",
      "Requirement already satisfied: httpx in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.40.1)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.16.0)\n",
      "Requirement already satisfied: ftfy in /usr/local/python/3.10.13/lib/python3.10/site-packages (from clip==1.0) (6.2.3)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from clip==1.0) (24.1)\n",
      "Requirement already satisfied: regex in /usr/local/python/3.10.13/lib/python3.10/site-packages (from clip==1.0) (2024.7.24)\n",
      "Requirement already satisfied: torch in /usr/local/python/3.10.13/lib/python3.10/site-packages (from clip==1.0) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/python/3.10.13/lib/python3.10/site-packages (from clip==1.0) (0.19.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.0.13)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/codespace/.local/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from torch->clip==1.0) (3.15.4)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.0)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->clip==1.0) (12.6.20)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index) (4.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.8.2)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (4.4.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (3.7)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.62->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.62->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.62->llama-index) (1.4.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core==0.10.62->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core==0.10.62->llama-index) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.62->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.62->llama-index) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.62->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.62->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from dataclasses-json->llama-index-core==0.10.62->llama-index) (3.21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.62->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.62->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.62->llama-index) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio->httpx->llama-index-core==0.10.62->llama-index) (1.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.62->llama-index) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index llama-parse llama-index-multi-modal-llms-openai git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-11 20:40:46--  https://github.com/user-attachments/files/16461058/data.zip\n",
      "Resolving github.com (github.com)... 20.26.156.215\n",
      "Connecting to github.com (github.com)|20.26.156.215|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-repository-file-5c1aeb/835367238/16461058?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240811%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240811T204046Z&X-Amz-Expires=300&X-Amz-Signature=0f84f886c6a0dd95cd616851d7871abed95bd063f721a847ddeb987c899d2e37&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=835367238&response-content-disposition=attachment%3Bfilename%3Ddata.zip&response-content-type=application%2Fzip [following]\n",
      "--2024-08-11 20:40:46--  https://objects.githubusercontent.com/github-production-repository-file-5c1aeb/835367238/16461058?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240811%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240811T204046Z&X-Amz-Expires=300&X-Amz-Signature=0f84f886c6a0dd95cd616851d7871abed95bd063f721a847ddeb987c899d2e37&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=835367238&response-content-disposition=attachment%3Bfilename%3Ddata.zip&response-content-type=application%2Fzip\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8000291 (7.6M) [application/zip]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>]   7.63M  11.9MB/s    in 0.6s    \n",
      "\n",
      "2024-08-11 20:40:47 (11.9 MB/s) - ‘data.zip’ saved [8000291/8000291]\n",
      "\n",
      "Archive:  data.zip\n",
      "   creating: data/\n",
      "  inflating: data/smagora_instruction_manual.pdf  \n",
      "  inflating: data/tuffing_instruction_manual.pdf  \n",
      "  inflating: data/nordli_instruction_manual.pdf  \n",
      "  inflating: data/uppspel_instruction_manual.pdf  \n",
      "  inflating: data/fredde_instruction_manual.pdf  \n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/user-attachments/files/16461058/data.zip -O data.zip\n",
    "!unzip -o data.zip\n",
    "!rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up your OpenAI and LlamaCloud keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up LlamaParse. We will parse the PDF files into markdown and use the GPT-4o multimodal model to parse the PDFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from the parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    "    parsing_instruction=\"You are given IKEA assembly instruction manuals\",\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "\n",
    "def get_data_files(data_dir=DATA_DIR) -> list[str]:\n",
    "    files = []\n",
    "    for f in os.listdir(data_dir):\n",
    "        fname = os.path.join(data_dir, f)\n",
    "        if os.path.isfile(fname):\n",
    "            files.append(fname)\n",
    "    return files\n",
    "\n",
    "\n",
    "files = get_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into docs, and save images from PDFs into `data_images` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing files:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 6ee13e2f-7cbc-4e48-9e6e-1cc7457671e7\n",
      "Started parsing the file under job_id be838cd0-34f0-461a-88cb-c058b0fe0536\n",
      "Started parsing the file under job_id e2e73452-4caa-449e-9143-16f9142e9447\n",
      "Started parsing the file under job_id 13422c96-3546-49d2-9081-55dbab21717a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing files:  20%|██        | 1/5 [00:02<00:10,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 5a9b18b6-adf5-476e-b105-39118aad60e7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing files: 100%|██████████| 5/5 [00:12<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Image for page 1: [{'name': 'page-0.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 2: [{'name': 'page-1.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 3: [{'name': 'page-2.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 4: [{'name': 'page-3.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 5: [{'name': 'page-4.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 6: [{'name': 'page-5.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 7: [{'name': 'page-6.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 8: [{'name': 'page-7.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 9: [{'name': 'page-8.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 10: [{'name': 'page-9.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 11: [{'name': 'page-10.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 12: [{'name': 'page-11.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 13: [{'name': 'page-12.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 14: [{'name': 'page-13.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 15: [{'name': 'page-14.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 16: [{'name': 'page-15.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 17: [{'name': 'page-16.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 18: [{'name': 'page-17.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 19: [{'name': 'page-18.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 20: [{'name': 'page-19.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 1: [{'name': 'page-0.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 2: [{'name': 'page-1.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 3: [{'name': 'page-2.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 4: [{'name': 'page-3.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 1: [{'name': 'page-0.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 2: [{'name': 'page-1.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 3: [{'name': 'page-2.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 4: [{'name': 'page-3.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 5: [{'name': 'page-4.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 6: [{'name': 'page-5.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 7: [{'name': 'page-6.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 8: [{'name': 'page-7.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 9: [{'name': 'page-8.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 10: [{'name': 'page-9.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 11: [{'name': 'page-10.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 12: [{'name': 'page-11.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 13: [{'name': 'page-12.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 14: [{'name': 'page-13.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 15: [{'name': 'page-14.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 16: [{'name': 'page-15.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 17: [{'name': 'page-16.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 18: [{'name': 'page-17.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 19: [{'name': 'page-18.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 20: [{'name': 'page-19.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 21: [{'name': 'page-20.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 22: [{'name': 'page-21.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 23: [{'name': 'page-22.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 24: [{'name': 'page-23.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 25: [{'name': 'page-24.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 26: [{'name': 'page-25.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 27: [{'name': 'page-26.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 28: [{'name': 'page-27.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 29: [{'name': 'page-28.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 30: [{'name': 'page-29.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 31: [{'name': 'page-30.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 32: [{'name': 'page-31.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 33: [{'name': 'page-32.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 34: [{'name': 'page-33.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 35: [{'name': 'page-34.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 36: [{'name': 'page-35.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 37: [{'name': 'page-36.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 1: [{'name': 'page-0.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 2: [{'name': 'page-1.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 3: [{'name': 'page-2.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 4: [{'name': 'page-3.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 5: [{'name': 'page-4.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 6: [{'name': 'page-5.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 7: [{'name': 'page-6.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 8: [{'name': 'page-7.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 9: [{'name': 'page-8.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 10: [{'name': 'page-9.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 11: [{'name': 'page-10.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 12: [{'name': 'page-11.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 13: [{'name': 'page-12.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 14: [{'name': 'page-13.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 15: [{'name': 'page-14.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 16: [{'name': 'page-15.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 17: [{'name': 'page-16.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 18: [{'name': 'page-17.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 19: [{'name': 'page-18.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 20: [{'name': 'page-19.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 21: [{'name': 'page-20.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 22: [{'name': 'page-21.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 23: [{'name': 'page-22.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 24: [{'name': 'page-23.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 25: [{'name': 'page-24.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 26: [{'name': 'page-25.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 27: [{'name': 'page-26.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 28: [{'name': 'page-27.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 29: [{'name': 'page-28.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 30: [{'name': 'page-29.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 31: [{'name': 'page-30.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 32: [{'name': 'page-31.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 1: [{'name': 'page-0.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 2: [{'name': 'page-1.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 3: [{'name': 'page-2.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 4: [{'name': 'page-3.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 5: [{'name': 'page-4.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 6: [{'name': 'page-5.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 7: [{'name': 'page-6.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 8: [{'name': 'page-7.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 9: [{'name': 'page-8.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 10: [{'name': 'page-9.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 11: [{'name': 'page-10.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 12: [{'name': 'page-11.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 13: [{'name': 'page-12.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 14: [{'name': 'page-13.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 15: [{'name': 'page-14.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 16: [{'name': 'page-15.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 17: [{'name': 'page-16.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 18: [{'name': 'page-17.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 19: [{'name': 'page-18.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
      "> Image for page 20: [{'name': 'page-19.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n"
     ]
    }
   ],
   "source": [
    "md_json_objs = parser.get_json_result(files)\n",
    "md_json_list = md_json_objs[0][\"pages\"]\n",
    "image_dicts = parser.get_images(md_json_objs, download_path=\"data_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper functions to create a list of `TextNode`s from the markdown tables to feed into the `VectorStoreIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = './mdobjects.json'\n",
    "import json\n",
    "with open(fn,'w') as f:\n",
    "    json.dump(md_json_objs, f)\n",
    "\n",
    "fn2 = './imagedicts.json'\n",
    "with open(fn2, 'w') as f:\n",
    "    json.dump(image_dicts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import typing as t\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "\n",
    "def get_page_number(file_name):\n",
    "    \"\"\"Gets page number of images using regex on file names\"\"\"\n",
    "    match = re.search(r\"-page-(\\d+)\\.jpg$\", str(file_name))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _get_sorted_image_files(image_dir):\n",
    "    \"\"\"Get image files sorted by page.\"\"\"\n",
    "    raw_files = [f for f in list(Path(image_dir).iterdir()) if f.is_file()]\n",
    "    sorted_files = sorted(raw_files, key=get_page_number)\n",
    "    return sorted_files\n",
    "\n",
    "\n",
    "def get_text_nodes(json_dicts, image_dir) -> t.List[TextNode]:\n",
    "    \"\"\"Creates nodes from json + images\"\"\"\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    docs = [doc[\"md\"] for doc in json_dicts]  # extract text\n",
    "    image_files = _get_sorted_image_files(image_dir)  # extract images\n",
    "\n",
    "    for idx, doc in enumerate(docs):\n",
    "        # adds both a text node and the corresponding image node (jpg of the page) for each page\n",
    "        node = TextNode(\n",
    "            text=doc,\n",
    "            metadata={\"image_path\": str(image_files[idx]), \"page_num\": idx + 1},\n",
    "        )\n",
    "        nodes.append(node)\n",
    "\n",
    "    return nodes\n",
    "\n",
    "\n",
    "text_nodes = get_text_nodes(md_json_list, \"data_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    "    Settings,\n",
    ")\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "llm = OpenAI(\"gpt-4o\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "if not os.path.exists(\"storage_ikea\"):\n",
    "    index = VectorStoreIndex(text_nodes, embed_model=embed_model)\n",
    "    index.storage_context.persist(persist_dir=\"./storage_ikea\")\n",
    "else:\n",
    "    ctx = StorageContext.from_defaults(persist_dir=\"./storage_ikea\")\n",
    "    index = load_index_from_storage(ctx)\n",
    "\n",
    "retriever = index.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom query engine that uses GPT-4o's multimodal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "from llama_index.core.schema import NodeWithScore, MetadataMode\n",
    "from llama_index.core.base.response.schema import Response\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.schema import ImageNode\n",
    "\n",
    "QA_PROMPT_TMPL = \"\"\"\\\n",
    "Below we give parsed text from slides in two different formats, as well as the image.\n",
    "\n",
    "We parse the text in both 'markdown' mode as well as 'raw text' mode. Markdown mode attempts \\\n",
    "to convert relevant diagrams into tables, whereas raw text tries to maintain the rough spatial \\\n",
    "layout of the text.\n",
    "\n",
    "Use the image information first and foremost. ONLY use the text/markdown information \n",
    "if you can't understand the image.\n",
    "\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query. Explain whether you got the answer\n",
    "from the parsed markdown or raw text or image, and if there's discrepancies, and your reasoning for the final answer.\n",
    "\n",
    "Query: {query_str}\n",
    "Answer: \"\"\"\n",
    "\n",
    "QA_PROMPT = PromptTemplate(QA_PROMPT_TMPL)\n",
    "\n",
    "gpt_4o_mm = OpenAIMultiModal(model=\"gpt-4o\", max_new_tokens=4096)\n",
    "\n",
    "\n",
    "class MultimodalQueryEngine(CustomQueryEngine):\n",
    "    qa_prompt: PromptTemplate\n",
    "    retriever: BaseRetriever\n",
    "    multi_modal_llm: OpenAIMultiModal\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        qa_prompt: PromptTemplate,\n",
    "        retriever: BaseRetriever,\n",
    "        multi_modal_llm: OpenAIMultiModal,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            qa_prompt=qa_prompt, retriever=retriever, multi_modal_llm=multi_modal_llm\n",
    "        )\n",
    "\n",
    "    def custom_query(self, query_str: str):\n",
    "        # retrieve most relevant nodes\n",
    "        nodes = self.retriever.retrieve(query_str)\n",
    "\n",
    "        # create image nodes from the image associated with those nodes\n",
    "        image_nodes = [\n",
    "            NodeWithScore(node=ImageNode(image_path=n.node.metadata[\"image_path\"]))\n",
    "            for n in nodes\n",
    "        ]\n",
    "\n",
    "        # create context string from parsed markdown text\n",
    "        ctx_str = \"\\n\\n\".join(\n",
    "            [r.node.get_content(metadata_mode=MetadataMode.LLM) for r in nodes]\n",
    "        )\n",
    "        # prompt for the LLM\n",
    "        fmt_prompt = self.qa_prompt.format(context_str=ctx_str, query_str=query_str)\n",
    "\n",
    "        # use the multimodal LLM to interpret images and generate a response to the prompt\n",
    "        llm_repsonse = self.multi_modal_llm.complete(\n",
    "            prompt=fmt_prompt,\n",
    "            image_documents=[image_node.node for image_node in image_nodes],\n",
    "        )\n",
    "        return Response(\n",
    "            response=str(llm_repsonse),\n",
    "            source_nodes=nodes,\n",
    "            metadata={\"text_nodes\": text_nodes, \"image_nodes\": image_nodes},\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a query engine instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = MultimodalQueryEngine(\n",
    "    qa_prompt=QA_PROMPT,\n",
    "    retriever=index.as_retriever(similarity_top_k=9),\n",
    "    multi_modal_llm=gpt_4o_mm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Example Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The query asks for the parts included in the Uppspel. However, the images provided are for different IKEA products (SMÅGÖRA, FREDDE, and TUFFING) and do not include any information about the Uppspel.\n",
       "\n",
       "Given the context information from the parsed markdown and raw text, there is no mention of Uppspel. The parts listed in the parsed text are for different sections labeled A, B, C2, and Additional Parts, but none of these sections are explicitly linked to Uppspel.\n",
       "\n",
       "Therefore, based on the provided images and text, there is no information available about the parts included in the Uppspel."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "response = query_engine.query(\"What parts are included in the Uppspel?\")\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The query asks about the appearance of the \"Tuffing.\" However, based on the provided images and parsed text, there is no mention or depiction of a product named \"Tuffing.\" The images and text primarily refer to products like \"NORDLI,\" \"FREDDE,\" and \"SMÅGÖRA.\"\n",
       "\n",
       "Therefore, I cannot provide an image or description of the \"Tuffing\" as it is not included in the provided materials. My conclusion is based on the images and the parsed text, which do not contain any reference to \"Tuffing.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What does the Tuffing look like?\")\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Step 4 of assembling the Nordli involves the following:\n",
       "\n",
       "- Insert 4x screws (117345) into the designated holes on the two panels as shown.\n",
       "\n",
       "This information was obtained from the parsed markdown text provided. The image associated with step 4 was not included in the provided images, so the text was used to determine the step. There were no discrepancies between the markdown and raw text for this step."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What is step 4 of assembling the Nordli?\")\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "If you are confused with reading the manual, you should refer to the manual itself for additional guidance. If you still need help, you can contact IKEA customer service.\n",
       "\n",
       "This information was derived from the image associated with the text:\n",
       "\n",
       "- \"If you have questions, refer to the manual.\"\n",
       "- \"If you still need help, contact IKEA customer service.\"\n",
       "\n",
       "There are no discrepancies between the parsed markdown/raw text and the image. The image clearly shows the instructions for seeking help if you are confused."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What should I do if I'm confused with reading the manual?\"\n",
    ")\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create an agent around the query engine and chat with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "query_engine_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"query_engine_tool\",\n",
    "    description=\"Useful for retrieving specific context from the data. Do NOT select if question asks for a summary of the data.\",\n",
    ")\n",
    "agent = FunctionCallingAgentWorker.from_tools(\n",
    "    [query_engine_tool], llm=llm, verbose=True\n",
    ").as_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Give a step-by-step instruction guide on how to assemble the Smagora\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: query_engine_tool with args: {\"input\": \"step-by-step instruction guide on how to assemble the Smagora\"}\n",
      "=== Function Output ===\n",
      "The provided images and parsed text do not contain any specific instructions for assembling a product named \"Smagora.\" The images and text provided are related to different IKEA products and their assembly instructions, but none of them mention \"Smagora.\"\n",
      "\n",
      "Therefore, I cannot provide a step-by-step instruction guide for assembling the \"Smagora\" based on the given information. If you have the specific instructions or images for \"Smagora,\" please provide them, and I can assist you further.\n",
      "=== Calling Function ===\n",
      "Calling function: query_engine_tool with args: {\"input\": \"Smagora assembly instructions\"}\n",
      "=== Function Output ===\n",
      "The query \"Smagora assembly instructions\" does not match any of the provided images or parsed text. The images and text provided are related to IKEA assembly instructions for different furniture items, but none of them mention \"Smagora.\"\n",
      "\n",
      "Therefore, based on the provided information, there are no assembly instructions for \"Smagora.\" If you have any other specific details or need instructions for a different item, please provide more information.\n",
      "=== LLM Response ===\n",
      "It appears that there are no available instructions for assembling a product named \"Smagora\" in the provided data. If you have any specific details or additional information about the product, please share them, and I will do my best to assist you further. Alternatively, if you have access to the product manual or any images related to the assembly, those would be helpful as well.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "It appears that there are no available instructions for assembling a product named \"Smagora\" in the provided data. If you have any specific details or additional information about the product, please share them, and I will do my best to assist you further. Alternatively, if you have access to the product manual or any images related to the assembly, those would be helpful as well."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Give a step-by-step instruction guide on how to assemble the Smagora\"\n",
    ")\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: How do I assemble the Fredde?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: query_engine_tool with args: {\"input\": \"Fredde assembly instructions\"}\n",
      "=== Function Output ===\n",
      "The query asks for the assembly instructions for the \"Fredde\" furniture. Based on the provided images and parsed text, there is no direct mention or image of the \"Fredde\" assembly instructions. The images and text provided refer to various other furniture assembly instructions, but none specifically for \"Fredde.\"\n",
      "\n",
      "Therefore, I cannot provide the assembly instructions for \"Fredde\" from the given information. If you have the specific manual or images for \"Fredde,\" please provide them, and I can assist you further.\n",
      "=== Calling Function ===\n",
      "Calling function: query_engine_tool with args: {\"input\": \"IKEA Fredde assembly instructions\"}\n",
      "=== Function Output ===\n",
      "The query asks for IKEA Fredde assembly instructions. Based on the provided images and parsed text, the instructions for IKEA Fredde are not included. The images and text provided are for different IKEA products, such as NORDLI and other unspecified furniture pieces.\n",
      "\n",
      "The images provided show various assembly steps and tools required for different IKEA products, but none of them specifically mention or show the IKEA Fredde desk.\n",
      "\n",
      "Therefore, the answer is that the IKEA Fredde assembly instructions are not included in the provided images or text.\n",
      "\n",
      "This conclusion is drawn from the images and the parsed text, which do not mention or depict the IKEA Fredde desk.\n",
      "=== LLM Response ===\n",
      "It seems that the assembly instructions for the IKEA Fredde desk are not available in the provided data. However, you can typically find the assembly instructions for IKEA products on their official website or in the manual that comes with the product.\n",
      "\n",
      "Here are general steps you can follow to assemble the IKEA Fredde desk:\n",
      "\n",
      "1. **Unpack the Components:**\n",
      "   - Lay out all the parts and hardware included in the package.\n",
      "   - Check the instruction manual to ensure you have all the necessary components.\n",
      "\n",
      "2. **Prepare Your Tools:**\n",
      "   - You will typically need a screwdriver (both flathead and Phillips), a hammer, and possibly an Allen wrench (usually included in the package).\n",
      "\n",
      "3. **Assemble the Frame:**\n",
      "   - Start by assembling the main frame of the desk. This usually involves connecting the side panels to the back panel.\n",
      "   - Use the provided screws and dowels to secure the panels together.\n",
      "\n",
      "4. **Attach the Shelves:**\n",
      "   - Follow the instructions to attach the shelves to the frame. This may include the main desk surface and any additional shelves for monitors or accessories.\n",
      "   - Ensure that each shelf is level and securely fastened.\n",
      "\n",
      "5. **Install the Legs:**\n",
      "   - Attach the legs to the bottom of the desk frame. Make sure they are securely fastened and stable.\n",
      "\n",
      "6. **Add Accessories:**\n",
      "   - If the desk includes any additional accessories such as cable management systems or monitor stands, attach these according to the instructions.\n",
      "\n",
      "7. **Final Adjustments:**\n",
      "   - Check all screws and connections to ensure everything is tight and secure.\n",
      "   - Adjust the desk to its final position and make sure it is level.\n",
      "\n",
      "8. **Clean Up:**\n",
      "   - Remove any packaging materials and tools from the assembly area.\n",
      "   - Wipe down the desk to remove any dust or fingerprints.\n",
      "\n",
      "If you need the specific manual for the IKEA Fredde desk, you can usually download it from the [IKEA website](https://www.ikea.com) by searching for the product name and looking for the assembly instructions PDF.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "It seems that the assembly instructions for the IKEA Fredde desk are not available in the provided data. However, you can typically find the assembly instructions for IKEA products on their official website or in the manual that comes with the product.\n",
       "\n",
       "Here are general steps you can follow to assemble the IKEA Fredde desk:\n",
       "\n",
       "1. **Unpack the Components:**\n",
       "   - Lay out all the parts and hardware included in the package.\n",
       "   - Check the instruction manual to ensure you have all the necessary components.\n",
       "\n",
       "2. **Prepare Your Tools:**\n",
       "   - You will typically need a screwdriver (both flathead and Phillips), a hammer, and possibly an Allen wrench (usually included in the package).\n",
       "\n",
       "3. **Assemble the Frame:**\n",
       "   - Start by assembling the main frame of the desk. This usually involves connecting the side panels to the back panel.\n",
       "   - Use the provided screws and dowels to secure the panels together.\n",
       "\n",
       "4. **Attach the Shelves:**\n",
       "   - Follow the instructions to attach the shelves to the frame. This may include the main desk surface and any additional shelves for monitors or accessories.\n",
       "   - Ensure that each shelf is level and securely fastened.\n",
       "\n",
       "5. **Install the Legs:**\n",
       "   - Attach the legs to the bottom of the desk frame. Make sure they are securely fastened and stable.\n",
       "\n",
       "6. **Add Accessories:**\n",
       "   - If the desk includes any additional accessories such as cable management systems or monitor stands, attach these according to the instructions.\n",
       "\n",
       "7. **Final Adjustments:**\n",
       "   - Check all screws and connections to ensure everything is tight and secure.\n",
       "   - Adjust the desk to its final position and make sure it is level.\n",
       "\n",
       "8. **Clean Up:**\n",
       "   - Remove any packaging materials and tools from the assembly area.\n",
       "   - Wipe down the desk to remove any dust or fingerprints.\n",
       "\n",
       "If you need the specific manual for the IKEA Fredde desk, you can usually download it from the [IKEA website](https://www.ikea.com) by searching for the product name and looking for the assembly instructions PDF."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.chat(\"How do I assemble the Fredde?\")\n",
    "display(Markdown(str(response)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-parse-5ZmnAQ0r-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
