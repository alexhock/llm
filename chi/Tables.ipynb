{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecc53da0-a501-4e2a-b6bb-b5fa744df1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install unstructured[pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e33a18-ff5f-4291-898d-97184a7ce734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "#elements = partition_pdf(filename=\"llama2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17adddf2-cea7-4041-a8ee-408c127820a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585477ea-08c3-4196-b295-ff92aaa3e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_and_tables(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        extracted_text = \"\"\n",
    "        tables = []\n",
    "        t=[]\n",
    "        for page in pdf.pages:\n",
    "            # Extract text\n",
    "            #extracted_text += page.extract_text()\n",
    "            t.append(page.extract_text())\n",
    "\n",
    "            # Extract tables\n",
    "            page_tables = page.extract_tables()\n",
    "            tables.extend(page_tables)\n",
    "            \n",
    "    return extracted_text, tables, t\n",
    "\n",
    "# Example usage\n",
    "pdf_path=\"llama2.pdf\"\n",
    "text, tables, pages = extract_text_and_tables(pdf_path)\n",
    "\n",
    "# Print extracted text\n",
    "#print(\"Extracted Text:\\n\", text)\n",
    "\n",
    "# Print extracted tables\n",
    "#for i, table in enumerate(tables):\n",
    "#    print(f\"Table {i+1}:\")\n",
    "#    for row in table:\n",
    "#        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374f80a1-3d12-43de-8751-12686a5915ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size GSM8k MATH\n",
      "7B 6.8 3.0\n",
      "MPT\n",
      "30B 15.2 3.1\n",
      "7B 6.8 2.3\n",
      "Falcon\n",
      "40B 19.6 5.5\n",
      "7B 11.0 2.9\n",
      "13B 17.8 3.9\n",
      "Llama1\n",
      "33B 35.6 7.1\n",
      "65B 50.9 10.6\n",
      "7B 14.6 2.5\n",
      "13B 28.7 3.9\n",
      "Llama2\n",
      "34B 42.2 6.24\n",
      "70B 56.8 13.5\n",
      "Table25: Comparisontootheropen-sourcemodelsonmathematicalreasoningtasks,GSM8kandMATH\n",
      "(maj1@1isreported).\n",
      "MathematicalReasoning. InTable25,wereportresultsforLlama2andotheropen-sourcedatasetsonthe\n",
      "GSM8kandMATHtasks.\n",
      "A.3 AdditionalDetailsforFine-tuning\n",
      "A.3.1 DetailedStatisticsofMetaHumanPreferenceData\n",
      "Table26showsdetailedstatisticsonMetahumanpreferencedata. Intotal,wecollected14batchesofhuman\n",
      "preferencedata(i.e.,MetaSafety+Helpfulness)onaweeklybasis,consistingofover1millionbinarymodel\n",
      "generationcomparisons. Ingeneral,laterbatchescontainmoresamplesasweonboardmoreannotatorsover\n",
      "timeandtheannotatorsalsobecomemorefamiliarwiththetasksandthushavebetterworkefficiency. We\n",
      "alsointentionallycollectmoremulti-turnsamplestoincreasethecomplexityofRLHFdataandthusthe\n",
      "averagenumberoftokenspersamplealsoincreaseaccordinglyoverbatches.\n",
      "InFigure25, weplotoutthepreferenceratingchangeoverbatches. Itcanbeclearlyseenthattheshare\n",
      "ofsampleswithsimilarresponses(e.g., negligiblybetterorunsure)increasedramaticallyovertimewhile\n",
      "thosewithstrongerpreference(e.g.,significantlybetter)dropinthemeantime. Thisreflectsthenatureofour\n",
      "iterativemodelupdateandpreferencedataannotationprocedure-withbetter-performingLlama2-Chat\n",
      "modelsusedforresponsesamplingovertime,itbecomeschallengingforannotatorstoselectabetterone\n",
      "fromtwoequallyhigh-qualityresponses.\n",
      "A.3.2 CurriculumStrategyforMetaHumanPreferenceData\n",
      "High quality data is critical for alignment as discussed for SFT. We worked closely with the annotation\n",
      "platformsduringourfine-tuningprocess,andoptedforacurriculumannotationstrategy. Withthefirst\n",
      "model,theannotatorswereaskedtomakepromptsrelativelysimple,andthentoprogressivelymovetowards\n",
      "morecomplexpromptsandteachingnewskillstoLlama2-Chat. Anillustrationofthiscurriculumannotation\n",
      "onourhelpfulnesspreferencedataisdisplayedinFigure26.\n",
      "A.3.3 AblationonRankingLosswithPreferenceRating-basedMarginforRewardModeling\n",
      "Weablatedtherankinglosswiththepreferencerating-basedmargintermforthehelpfulnessrewardmodel.\n",
      "Wetriedtwovariantsofm(r)withdifferentmagnitudeforthemarginterminEq2aslistedopen-source27\n",
      "andcomparethemagainstthebaselinewithoutthemarginterm. Wereportboththeirper-ratingandaverage\n",
      "accuracyontheMetaHelpfultestsetinTable28. Weobservethatthemargintermcanindeedhelpthe\n",
      "rewardmodelperformbetteronmoreseparablecomparisonpairsandalargermargincanboostitfurther.\n",
      "However,thelargermarginalsoregressesperformanceonsimilarsamples.\n",
      "We further evaluated the impact of margin-based loss on reward score distribution shifts. We plot the\n",
      "histogramofrewardscoresfromthetestsetinFigure27. Essentially,themargintermpushesthereward\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "print(pages[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "184713a0-7ff1-443f-a61a-e599e6ed1b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-07 10:35:39--  https://arxiv.org/pdf/2307.09288.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.131.42, 151.101.3.42, 151.101.67.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.131.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://arxiv.org/pdf/2307.09288 [following]\n",
      "--2024-08-07 10:35:39--  http://arxiv.org/pdf/2307.09288\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.131.42|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13661300 (13M) [application/pdf]\n",
      "Saving to: ‘llama2.pdf’\n",
      "\n",
      "llama2.pdf          100%[===================>]  13.03M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2024-08-07 10:35:39 (146 MB/s) - ‘llama2.pdf’ saved [13661300/13661300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Table%20Transformer/Inference_with_Table_Transformer_(TATR)_for_parsing_tables.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9628ed8a-7e50-49c4-a774-ecefa8b6002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Patch\n",
    "import io\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from transformers import AutoModelForObjectDetection\n",
    "import torch\n",
    "import openai\n",
    "import os\n",
    "import fitz\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "OPENAI_API_TOKEN = \"sk-<your-openai-api-token>\"\n",
    "openai.api_key = OPENAI_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7399db6-e9d9-4599-9ba2-62040b0ca3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = \"llama2.pdf\"\n",
    "\n",
    "# Split the base name and extension\n",
    "output_directory_path, _ = os.path.splitext(pdf_file)\n",
    "\n",
    "if not os.path.exists(output_directory_path):\n",
    "    os.makedirs(output_directory_path)\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_document = fitz.open(pdf_file)\n",
    "\n",
    "# Iterate through each page and convert to an image\n",
    "for page_number in range(pdf_document.page_count):\n",
    "    # Get the page\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Convert the page to an image\n",
    "    pix = page.get_pixmap()\n",
    "\n",
    "    # Create a Pillow Image object from the pixmap\n",
    "    image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    # Save the image\n",
    "    image.save(f\"./{output_directory_path}/page_{page_number + 1}.png\")\n",
    "\n",
    "# Close the PDF file\n",
    "pdf_document.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d7f70f-f81d-4e0f-bbe2-b47a5cf6b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://docs.llamaindex.ai/en/v0.9.48/examples/multi_modal/multi_modal_pdf_tables.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "054ba90d-2e3d-48ef-885b-c67005682760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9u2A3GrLzwjylNl2sLY4oPpERxHII', 'object': 'chat.completion', 'created': 1723141703, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '```markdown\\n# Contents\\n\\n1. Introduction ......................................................... 3\\n\\n2. Pretraining .......................................................... 5  \\n   2.1 Pretraining Data ................................................. 5  \\n   2.2 Training Details ................................................. 5  \\n   2.3 LLAMA 2 Pretrained Model Evaluation ............................... 7  \\n\\n3. Fine-tuning ........................................................... 8  \\n   3.1 Supervised Fine-Tuning (SFT) ..................................... 9  \\n   3.2 Reinforcement Learning with Human Feedback (RLHF) .................. 9  \\n   3.3 System Message for Multi-Turn Consistency ........................ 16  \\n   3.4 RLHF Results .................................................... 17  \\n\\n4. Safety ............................................................... 20  \\n   4.1 Safety in Pretraining ............................................ 20  \\n   4.2 Safety Fine-Tuning ............................................... 23  \\n   4.3 Red Teaming ..................................................... 28  \\n   4.4 Safety Evaluation of LLAMA 2-CHAT ............................... 29  \\n\\n5. Discussion ........................................................... 32  \\n   5.1 Learnings and Observations ....................................... 32  \\n   5.2 Limitations and Ethical Considerations ............................ 34  \\n   5.3 Responsible Release Strategy .................................... 35  \\n\\n6. Related Work ......................................................... 35  \\n\\n7. Conclusion ........................................................... 36  \\n\\nA. Appendix ............................................................ 46  \\n   A.1 Contributions ................................................... 46  \\n   A.2 Additional Details for Pretraining ............................... 47  \\n   A.3 Additional Details for Fine-tuning ................................ 51  \\n   A.4 Additional Details for Safety .................................... 58  \\n   A.5 Data Annotation .................................................. 72  \\n   A.6 Dataset Contamination .......................................... 75  \\n   A.7 Model Card ....................................................... 77  \\n```', 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 25516, 'completion_tokens': 397, 'total_tokens': 25913}, 'system_fingerprint': 'fp_507c9469a1'}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "# OpenAI API key\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"./llama2/page_2.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"extract the contents of the image as markdown\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 3000\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a5030b-2e4c-4d8a-9a8c-b730416fe46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-zl_ccvyf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-zl_ccvyf\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting llama-index\n",
      "  Downloading llama_index-0.10.62-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting qdrant_client\n",
      "  Downloading qdrant_client-1.10.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pyMuPDF\n",
      "  Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting tools\n",
      "  Downloading tools-0.1.9.tar.gz (34 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting frontend\n",
      "  Downloading frontend-0.0.3-py3-none-any.whl.metadata (847 bytes)\n",
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core==0.10.62 (from llama-index)\n",
      "  Downloading llama_index_core-0.10.62-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl.metadata (650 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.32-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (6.0.1)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core==0.10.62->llama-index)\n",
      "  Downloading aiohttp-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.2.14)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.62->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (2024.6.1)\n",
      "Requirement already satisfied: httpx in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.26.4)\n",
      "Collecting openai>=1.1.0 (from llama-index-core==0.10.62->llama-index)\n",
      "  Downloading openai-1.40.1-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (8.5.0)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.62->llama-index)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-core==0.10.62->llama-index) (1.16.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from qdrant_client) (1.65.4)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant_client)\n",
      "  Downloading grpcio_tools-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from qdrant_client) (2.10.1)\n",
      "Collecting pydantic>=1.10.8 (from qdrant_client)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from qdrant_client) (2.0.7)\n",
      "Collecting PyMuPDFb==1.24.9 (from pyMuPDF)\n",
      "  Downloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting pytils (from tools)\n",
      "  Downloading pytils-0.4.1.tar.gz (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from tools) (1.16.0)\n",
      "Requirement already satisfied: lxml in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tools) (5.2.2)\n",
      "Collecting starlette>=0.12.0 (from frontend)\n",
      "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting uvicorn>=0.7.1 (from frontend)\n",
      "  Downloading uvicorn-0.30.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting itsdangerous>=1.1.0 (from frontend)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting aiofiles (from frontend)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ftfy (from clip==1.0)\n",
      "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from clip==1.0) (24.1)\n",
      "Requirement already satisfied: regex in /usr/local/python/3.10.13/lib/python3.10/site-packages (from clip==1.0) (2024.7.24)\n",
      "Requirement already satisfied: torch in /usr/local/python/3.10.13/lib/python3.10/site-packages (from clip==1.0) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/python/3.10.13/lib/python3.10/site-packages (from clip==1.0) (0.19.0)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from easyocr) (1.14.0)\n",
      "Collecting scikit-image (from easyocr)\n",
      "  Downloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr)\n",
      "  Downloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting Shapely (from easyocr)\n",
      "  Downloading shapely-2.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting pyclipper (from easyocr)\n",
      "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant_client) (5.27.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant_client) (68.2.2)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (4.4.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (3.7)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.62->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.62->llama-index) (0.14.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
      "  Downloading llama_cloud-0.0.13-py3-none-any.whl.metadata (751 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/codespace/.local/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.3.1)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
      "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.10.8->qdrant_client)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic>=1.10.8->qdrant_client)\n",
      "  Downloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from torch->clip==1.0) (3.15.4)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.0)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from torch->clip==1.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->clip==1.0) (12.6.20)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from uvicorn>=0.7.1->frontend) (8.1.7)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/codespace/.local/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Collecting imageio>=2.33 (from scikit-image->easyocr)\n",
      "  Downloading imageio-2.34.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr)\n",
      "  Downloading tifffile-2024.7.24-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading aiohappyeyeballs-2.3.5-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio->httpx->llama-index-core==0.10.62->llama-index) (1.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.62->llama-index) (1.4.2)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.1.0->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.62->llama-index) (3.3.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.62->llama-index)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.62->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from dataclasses-json->llama-index-core==0.10.62->llama-index) (3.21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.62->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.62->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.62->llama-index) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
      "Downloading llama_index-0.10.62-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_core-0.10.62-py3-none-any.whl (15.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading qdrant_client-1.10.1-py3-none-any.whl (254 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading frontend-0.0.3-py3-none-any.whl (32 kB)\n",
      "Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_tools-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
      "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.1.29-py3-none-any.whl (11 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.32-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.5-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.34.2-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading llama_cloud-0.0.13-py3-none-any.whl (169 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Downloading openai-1.40.1-py3-none-any.whl (360 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.4/360.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tifffile-2024.7.24-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.2/226.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.3.5-py3-none-any.whl (12 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: tools, clip, pytils\n",
      "  Building wheel for tools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tools: filename=tools-0.1.9-py3-none-any.whl size=46731 sha256=28955db7ec7c9d2e3c29197170f389f52d8cfc9e68b3845e4925efc37adfdb9b\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/c0/d0/70/a33bd4bed2af4f7038b038c16faab552cd0e9d9f4125223a71\n",
      "  Building wheel for clip (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369492 sha256=41981743e5dca7423e98d3635b4f8213c93a4f2522cd96b5a335422c8080660d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-aa77o_op/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
      "  Building wheel for pytils (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytils: filename=pytils-0.4.1-py3-none-any.whl size=32868 sha256=dba01e451df2a366e2dc6388d7d704f03b4fec03eef968dafefe061e0ef5c836\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/5a/eb/7c/3b6f0c25815749883152b2caca34c35dbaab13ec2864270cbd\n",
      "Successfully built tools clip pytils\n",
      "Installing collected packages: striprtf, python-bidi, pyclipper, ninja, dirtyjson, uvicorn, tifffile, Shapely, pytils, PyMuPDFb, pydantic-core, opencv-python-headless, multidict, lazy-loader, jiter, itsdangerous, imageio, hyperframe, hpack, grpcio-tools, greenlet, ftfy, frozenlist, distro, async-timeout, annotated-types, aiohappyeyeballs, aiofiles, yarl, tools, tiktoken, starlette, SQLAlchemy, scikit-image, pyMuPDF, pydantic, h2, aiosignal, openai, llama-cloud, frontend, aiohttp, qdrant_client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, easyocr, clip, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed PyMuPDFb-1.24.9 SQLAlchemy-2.0.32 Shapely-2.0.5 aiofiles-24.1.0 aiohappyeyeballs-2.3.5 aiohttp-3.10.1 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 clip-1.0 dirtyjson-1.0.8 distro-1.9.0 easyocr-1.7.1 frontend-0.0.3 frozenlist-1.4.1 ftfy-6.2.3 greenlet-3.0.3 grpcio-tools-1.65.4 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 imageio-2.34.2 itsdangerous-2.2.0 jiter-0.5.0 lazy-loader-0.4 llama-cloud-0.0.13 llama-index-0.10.62 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.62 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.29 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.32 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 multidict-6.0.5 ninja-1.11.1.1 openai-1.40.1 opencv-python-headless-4.10.0.84 pyMuPDF-1.24.9 pyclipper-1.3.0.post5 pydantic-2.8.2 pydantic-core-2.20.1 python-bidi-0.6.0 pytils-0.4.1 qdrant_client-1.10.1 scikit-image-0.24.0 starlette-0.38.2 striprtf-0.0.26 tifffile-2024.7.24 tiktoken-0.7.0 tools-0.1.9 uvicorn-0.30.5 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index qdrant_client pyMuPDF tools frontend git+https://github.com/openai/CLIP.git easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b38eb7-eac9-44b5-876a-aebb83d9bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxResize(object):\n",
    "    def __init__(self, max_size=800):\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        width, height = image.size\n",
    "        current_max_size = max(width, height)\n",
    "        scale = self.max_size / current_max_size\n",
    "        resized_image = image.resize(\n",
    "            (int(round(scale * width)), int(round(scale * height)))\n",
    "        )\n",
    "\n",
    "        return resized_image\n",
    "\n",
    "\n",
    "detection_transform = transforms.Compose(\n",
    "    [\n",
    "        MaxResize(800),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "structure_transform = transforms.Compose(\n",
    "    [\n",
    "        MaxResize(1000),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load table detection model\n",
    "# processor = TableTransformerImageProcessor(max_size=800)\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"microsoft/table-transformer-detection\", revision=\"no_timm\"\n",
    ").to(device)\n",
    "\n",
    "# load table structure recognition model\n",
    "# structure_processor = TableTransformerImageProcessor(max_size=1000)\n",
    "structure_model = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"microsoft/table-transformer-structure-recognition-v1.1-all\"\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(-1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h), (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    width, height = size\n",
    "    boxes = box_cxcywh_to_xyxy(out_bbox)\n",
    "    boxes = boxes * torch.tensor(\n",
    "        [width, height, width, height], dtype=torch.float32\n",
    "    )\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def outputs_to_objects(outputs, img_size, id2label):\n",
    "    m = outputs.logits.softmax(-1).max(-1)\n",
    "    pred_labels = list(m.indices.detach().cpu().numpy())[0]\n",
    "    pred_scores = list(m.values.detach().cpu().numpy())[0]\n",
    "    pred_bboxes = outputs[\"pred_boxes\"].detach().cpu()[0]\n",
    "    pred_bboxes = [\n",
    "        elem.tolist() for elem in rescale_bboxes(pred_bboxes, img_size)\n",
    "    ]\n",
    "\n",
    "    objects = []\n",
    "    for label, score, bbox in zip(pred_labels, pred_scores, pred_bboxes):\n",
    "        class_label = id2label[int(label)]\n",
    "        if not class_label == \"no object\":\n",
    "            objects.append(\n",
    "                {\n",
    "                    \"label\": class_label,\n",
    "                    \"score\": float(score),\n",
    "                    \"bbox\": [float(elem) for elem in bbox],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return objects\n",
    "\n",
    "def detect_and_crop_save_table(\n",
    "    file_path, cropped_table_directory=\"./table_images/\"\n",
    "):\n",
    "    image = Image.open(file_path)\n",
    "\n",
    "    filename, _ = os.path.splitext(file_path.split(\"/\")[-1])\n",
    "\n",
    "    if not os.path.exists(cropped_table_directory):\n",
    "        os.makedirs(cropped_table_directory)\n",
    "\n",
    "    # prepare image for the model\n",
    "    # pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = detection_transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values)\n",
    "\n",
    "    # postprocess to get detected tables\n",
    "    id2label = model.config.id2label\n",
    "    id2label[len(model.config.id2label)] = \"no object\"\n",
    "    detected_tables = outputs_to_objects(outputs, image.size, id2label)\n",
    "\n",
    "    print(f\"number of tables detected {len(detected_tables)}\")\n",
    "\n",
    "    for idx in range(len(detected_tables)):\n",
    "        #   # crop detected table out of image\n",
    "        cropped_table = image.crop(detected_tables[idx][\"bbox\"])\n",
    "        cropped_table.save(f\"./{cropped_table_directory}/{filename}_{idx}.png\")\n",
    "\n",
    "def plot_images(image_paths):\n",
    "    images_shown = 0\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for img_path in image_paths:\n",
    "        if os.path.isfile(img_path):\n",
    "            image = Image.open(img_path)\n",
    "\n",
    "            plt.subplot(2, 3, images_shown + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            images_shown += 1\n",
    "            if images_shown >= 9:\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a090fe8-a01f-4303-a78d-8d5847f53e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in retrieved_images:\n",
    "    detect_and_crop_save_table(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62773545-2acc-4c6f-84b0-753782f2ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cropped tables\n",
    "image_documents = SimpleDirectoryReader(\"./table_images/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fe2e1-af75-43c7-9ee3-2dd4964c71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "# put your local directore here\n",
    "#documents_images_v2 = SimpleDirectoryReader(\"./llama2/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa91b8d-f8b6-437f-bf9b-4b7cd15162cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_mm_llm = OpenAIMultiModal(\n",
    "    model=\"gpt-4-vision-preview\", api_key=OPENAI_API_TOKEN, max_new_tokens=1500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468cff40-d06a-42e5-ba69-4810e30513f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_mm_llm.complete(\n",
    "    prompt=\"Compare llama2 with llama1?\",\n",
    "    image_documents=image_documents,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf617f-448b-41ec-a284-c697429f6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "table_images_paths = glob.glob(\"./table_images/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f1b3b-5f97-4ca1-acc0-6407e3ec663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(table_images_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
